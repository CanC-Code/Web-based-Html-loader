<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Video Layer — Stable Editor</title>
<link rel="stylesheet" href="style.css">
<style>
  :root{
    --bg:#0d1117; --panel:#0f1720; --muted:#8b949e; --accent:#58a6ff; --btn:#238636;
  }
  html,body{height:100%; margin:0;}
  body {
    background:var(--bg);
    color:#c9d1d9;
    font-family:Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
    display:flex;
    flex-direction:column;
    align-items:center;
    padding:12px;
    box-sizing:border-box;
  }

  header { width:100%; max-width:920px; margin-bottom:8px; text-align:center;}
  h1 { margin:0; color:var(--accent); font-size:1.1rem; }
  p.lead { margin:6px 0 0 0; color:var(--muted); font-size:0.95rem; }

  main { width:100%; max-width:920px; display:flex; flex-direction:column; gap:12px; align-items:stretch; }

  /* Containers */
  .mediaBox { background:#07080a; border:1px solid #16181c; border-radius:12px; padding:10px; box-sizing:border-box; }
  .mediaInner { display:flex; flex-direction:column; gap:10px; align-items:center; }

  video, canvas {
    width:100%;
    max-width:820px;
    border-radius:10px;
    background:#000;
    display:block;
  }

  /* Controls placed below media — no overlap */
  .controls {
    display:flex;
    gap:8px;
    flex-wrap:wrap;
    justify-content:center;
    padding:10px;
    border-radius:10px;
    background:linear-gradient(180deg,#0b0d10,#071013);
    border:1px solid #111317;
  }

  .controls > * { min-width:120px; flex:1 1 auto; }

  button, select, input[type="file"] {
    appearance:none;
    -webkit-appearance:none;
    background:var(--btn);
    color:#fff;
    border:none;
    padding:10px 12px;
    border-radius:8px;
    font-weight:700;
    cursor:pointer;
    font-size:1rem;
  }

  button:disabled { background:#2f3338; opacity:0.7; cursor:not-allowed; }

  .aux { background:#111315; color:var(--muted); font-weight:600; }

  .progressWrap { width:100%; margin-top:8px; }
  .progress {
    width:100%; height:8px; background:#0b0b0b; border-radius:6px; overflow:hidden; border:1px solid #151619;
  }
  .progress > div { height:100%; width:0%; background:linear-gradient(90deg,#3bd, #58a6ff); transition:width 0.12s linear; }

  #status { margin-top:10px; color:var(--muted); font-size:0.95rem; text-align:center; word-break:break-word; }

  @media(max-width:640px){
    .controls { gap:6px; }
    button, select, input[type="file"] { font-size:0.95rem; padding:10px; min-width:unset; width:100%; }
  }
</style>
</head>
<body>
<header>
  <h1>Video Layer — Stable Editor</h1>
  <p class="lead">Load a video, press Start, wait for processing to run, then Save. Controls won’t overlap content.</p>
</header>

<main>
  <section class="mediaBox">
    <div class="mediaInner">
      <label style="width:100%; text-align:center;">
        <input id="videoInput" type="file" accept="video/*" style="width:100%; padding:8px; border-radius:8px;" />
      </label>

      <video id="inputVideo" playsinline controls></video>

      <canvas id="outputCanvas" aria-label="Processed output"></canvas>
    </div>
  </section>

  <section class="controls" role="region" aria-label="Processing controls">
    <button id="startBtn">Start Processing</button>
    <button id="stopBtn" disabled>Stop</button>
    <button id="saveBtn" disabled>Save Video</button>
    <select id="modeSelect" class="aux" title="Processing mode">
      <option value="motion">Motion (moving objects)</option>
      <option value="all">All objects (segmentation)</option>
      <option value="human">People only</option>
    </select>
  </section>

  <div class="progressWrap">
    <div class="progress"><div id="progressFill"></div></div>
  </div>

  <div id="status">Ready.</div>
</main>

<!-- Detector module expected in the same folder (detector.js + detector-worker.js) -->
<script src="detector.js"></script>
<script>
/* Robust UI wiring for Detector-based processing.
   Assumes Detector exposes:
     - async Detector.init(options)
     - async Detector.processFrame(ImageData) -> mask (object) | null
     - Detector.applyMask(ctx, mask)
   If Detector is not present, user is prompted.
*/

const videoInput = document.getElementById('videoInput');
const inputVideo = document.getElementById('inputVideo');
const outCanvas = document.getElementById('outputCanvas');
const outCtx = outCanvas.getContext('2d');

const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const saveBtn = document.getElementById('saveBtn');
const modeSelect = document.getElementById('modeSelect');

const progressFill = document.getElementById('progressFill');
const statusEl = document.getElementById('status');

let processing = false;
let pendingProcess = null; // track single outstanding processFrame call
let recorder = null;
let recordedBlobs = [];

// UI helpers
function setStatus(s){ statusEl.textContent = s; console.log('[video_layer] ', s); }
function setProgress(p){ progressFill.style.width = `${Math.max(0, Math.min(100, p))}%`; }

// Video load handling
videoInput.addEventListener('change', e=>{
  const f = e.target.files[0];
  if(!f) return;
  inputVideo.src = URL.createObjectURL(f);
  inputVideo.load();
  inputVideo.onloadeddata = () => {
    // size canvas same as video
    outCanvas.width = inputVideo.videoWidth;
    outCanvas.height = inputVideo.videoHeight;

    // reset UI
    setStatus(`Loaded: ${inputVideo.videoWidth}×${inputVideo.videoHeight}`);
    setProgress(0);
    startBtn.disabled = false;
    stopBtn.disabled = true;
    saveBtn.disabled = true;
  };
});

// Start processing
startBtn.addEventListener('click', async ()=>{
  if(!inputVideo.src) { setStatus('Please choose a video file first.'); return; }
  if(typeof Detector === 'undefined') { setStatus('Detector module not found (detector.js).'); return; }

  startBtn.disabled = true;
  stopBtn.disabled = false;
  saveBtn.disabled = true;
  modeSelect.disabled = true;

  setStatus('Initializing Detector...');
  try {
    // give Detector the chosen mode if it supports options
    await Detector.init({ mode: modeSelect.value });
  } catch(err){
    console.error(err);
    setStatus('Detector.init failed: ' + (err && err.message ? err.message : String(err)));
    startBtn.disabled = false;
    stopBtn.disabled = true;
    modeSelect.disabled = false;
    return;
  }

  recordedBlobs = [];
  // start recording the processed canvas
  try {
    const stream = outCanvas.captureStream(25);
    recorder = new MediaRecorder(stream, { mimeType: 'video/webm;codecs=vp8' });
    recorder.ondataavailable = ev => { if(ev.data && ev.data.size) recordedBlobs.push(ev.data); };
    recorder.onstop = ()=> setStatus('Recording stopped — ready to save.');
    recorder.start(1000);
  } catch(err) {
    console.warn('MediaRecorder not available or failed:', err);
    recorder = null;
    setStatus('Warning: recording not available in this browser; you can still preview.');
  }

  processing = true;
  inputVideo.currentTime = 0;
  await inputVideo.play().catch(()=>{}); // play; user interaction may be required on some browsers

  setStatus('Processing started...');
  processLoop();
});

// Stop processing
stopBtn.addEventListener('click', ()=>{
  processing = false;
  startBtn.disabled = false;
  stopBtn.disabled = true;
  modeSelect.disabled = false;
  if(recorder && recorder.state === 'recording') recorder.stop();
  saveBtn.disabled = recordedBlobs.length === 0;
  setStatus('Processing stopped.');
});

// Save recorded video (WebM)
saveBtn.addEventListener('click', ()=>{
  if(recordedBlobs.length === 0){ setStatus('Nothing recorded yet.'); return; }
  const blob = new Blob(recordedBlobs, { type:'video/webm' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = `processed_${Date.now()}.webm`;
  a.click();
  setStatus('Saved processed video.');
});

// Throttled processing loop
let lastTimestamp = 0;
const targetMs = 100; // ~10 fps processing to keep mobile smooth

async function processLoop(timestamp){
  if(!processing) return;
  // draw current video frame to output as baseline
  outCtx.clearRect(0,0,outCanvas.width,outCanvas.height);
  outCtx.drawImage(inputVideo, 0, 0, outCanvas.width, outCanvas.height);

  // throttle: skip frames if called too soon
  if(performance.now() - lastTimestamp >= targetMs && !pendingProcess){
    lastTimestamp = performance.now();

    try {
      // grab ImageData and hand to Detector
      const frame = outCtx.getImageData(0,0,outCanvas.width,outCanvas.height);

      // call Detector.processFrame only when previous returned or if Detector handles queue internally
      pendingProcess = Detector.processFrame(frame, { mode: modeSelect.value })
        .catch(err=>{
          console.error('Detector.processFrame error:', err);
          return null;
        })
        .then(mask=>{
          pendingProcess = null;
          if(mask){
            try {
              // Detector.applyMask should composite mask over the current outCtx; pass ctx and mask
              Detector.applyMask(outCtx, mask);
            } catch(err){
              console.error('applyMask failed:', err);
            }
          }
        });
    } catch(err){
      console.error('processing frame failed:', err);
    }
  }

  // update progress bar from video play progress (provides visual feedback)
  if(inputVideo.duration && !isNaN(inputVideo.duration) && inputVideo.duration > 0){
    const pct = Math.min(100, (inputVideo.currentTime / inputVideo.duration) * 100);
    setProgress(pct);
  }

  // schedule next frame
  requestAnimationFrame(processLoop);
}

// Prevent accidental navigation while processing
window.addEventListener('beforeunload', (e)=>{
  if(processing){
    e.preventDefault();
    e.returnValue = '';
  }
});

// Safety: if Detector not present, show help
if(typeof Detector === 'undefined'){
  setStatus('Detector not loaded — ensure detector.js is included in the same folder.');
  startBtn.disabled = true;
}
</script>
</body>
</html>