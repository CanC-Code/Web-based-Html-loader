<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>AI Video Processor</title>
<link rel="stylesheet" href="style.css">
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.17"></script>
</head>
<body>

<header>
  <h1>AI Video Processor</h1>
  <p class="lead">Background removal & smart AI refinement preview</p>
</header>

<main>
  <div class="mediaBox">
    <div class="mediaInner">
      <input type="file" id="videoInput" accept="video/*">
      <video id="video" controls></video>
      <canvas id="canvas"></canvas>
    </div>
  </div>

  <div class="controls">
    <button id="processBtn">Process</button>
    <button id="playBtn" disabled>Play/Pause</button>
    <button id="downloadBtn" disabled>Download</button>
  </div>

  <div class="progressWrap">
    <div class="progress"><div id="progressBar"></div></div>
  </div>
  <div id="status">Load a video to begin.</div>
</main>

<script type="module">
import { FilesetResolver, ImageSegmenter } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.17";

const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const input = document.getElementById("videoInput");
const processBtn = document.getElementById("processBtn");
const playBtn = document.getElementById("playBtn");
const downloadBtn = document.getElementById("downloadBtn");
const progressBar = document.getElementById("progressBar");
const status = document.getElementById("status");

let segmenter, processedFrames = [], frameRate = 30, processing = false, processedBlob = null;

// ðŸŸ¦ Load model
const filesetResolver = await FilesetResolver.forVisionTasks(
  "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.17/wasm"
);
segmenter = await ImageSegmenter.createFromOptions(filesetResolver, {
  baseOptions: {
    modelAssetPath: "https://storage.googleapis.com/mediapipe-assets/selfie_segmenter_landscape.tflite"
  },
  outputCategoryMask: true,
});
status.textContent = "Model loaded successfully.";

// ðŸŸ© Load video
input.addEventListener("change", e => {
  const file = e.target.files[0];
  if (!file) return;
  video.src = URL.createObjectURL(file);
  video.load();
  video.onloadeddata = () => {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    frameRate = video.duration ? Math.ceil(video.videoWidth / video.videoHeight) * 10 : 30;
    status.textContent = "Video ready. Click Process to begin.";
    processBtn.disabled = false;
  };
});

// ðŸŸ¨ Process video
processBtn.addEventListener("click", async () => {
  if (!segmenter || processing) return;
  processing = true;
  processedFrames = [];
  progressBar.style.width = "0%";
  status.textContent = "Processing...";

  const offscreen = new OffscreenCanvas(canvas.width, canvas.height);
  const octx = offscreen.getContext("2d");

  const capture = new ImageCapture(video.captureStream().getVideoTracks()[0]);
  const totalFrames = Math.floor(video.duration * frameRate);
  let frameIndex = 0;

  const processFrame = async () => {
    if (!processing) return;
    const bitmap = await capture.grabFrame();
    octx.drawImage(bitmap, 0, 0, offscreen.width, offscreen.height);

    const result = segmenter.segment(octx.canvas);
    const mask = await result.categoryMask;
    const maskCanvas = document.createElement("canvas");
    maskCanvas.width = mask.width;
    maskCanvas.height = mask.height;
    const maskCtx = maskCanvas.getContext("2d");
    const maskImage = maskCtx.getImageData(0, 0, mask.width, mask.height);
    maskImage.data.set(await mask.getAsUint8Array());
    maskCtx.putImageData(maskImage, 0, 0);

    // composite mask
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(octx.canvas, 0, 0);
    ctx.save();
    ctx.globalCompositeOperation = "destination-in";
    ctx.drawImage(maskCanvas, 0, 0, canvas.width, canvas.height);
    ctx.restore();

    const frame = canvas.toDataURL("image/webp");
    processedFrames.push(frame);

    frameIndex++;
    progressBar.style.width = `${(frameIndex / totalFrames) * 100}%`;

    if (frameIndex < totalFrames) {
      requestAnimationFrame(processFrame);
    } else {
      processing = false;
      createProcessedVideo();
    }
  };

  video.play();
  await new Promise(r => setTimeout(r, 300)); // warm up
  requestAnimationFrame(processFrame);
});

// ðŸŸ¥ Create playable processed video
function createProcessedVideo() {
  const blobParts = processedFrames.map(f => fetch(f).then(r => r.blob()));
  Promise.all(blobParts).then(async blobs => {
    const fullBlob = new Blob(blobs, { type: "video/webm" });
    processedBlob = fullBlob;
    const url = URL.createObjectURL(fullBlob);
    const processed = document.createElement("video");
    processed.src = url;
    processed.controls = true;
    processed.autoplay = false;
    processed.loop = false;
    processed.style.width = "100%";
    video.replaceWith(processed);
    processed.id = "processedVideo";
    status.textContent = "Processing complete. You can play or download the result.";
    playBtn.disabled = false;
    downloadBtn.disabled = false;
  });
}

// ðŸŽ® Playback and download
playBtn.addEventListener("click", () => {
  const processed = document.getElementById("processedVideo");
  if (processed.paused) processed.play();
  else processed.pause();
});

downloadBtn.addEventListener("click", () => {
  if (!processedBlob) return;
  const a = document.createElement("a");
  a.href = URL.createObjectURL(processedBlob);
  a.download = "processed_video.webm";
  a.click();
});
</script>
</body>
</html>