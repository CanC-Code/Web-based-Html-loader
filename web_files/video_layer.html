<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>Video Layer — Multi-Object Segmentation</title>

<style>
  :root {
    --bg: #0d1117; --panel: #161b22; --muted: #8b949e;
    --accent: #58a6ff; --btn: #238636;
  }
  body {
    margin:0; font-family: Inter, Arial, sans-serif;
    background:var(--bg); color:#c9d1d9;
    display:flex; flex-direction:column; align-items:center;
    padding:1rem;
  }
  h1{ color:var(--accent); margin:0 0 0.75rem 0; font-size:1.2rem; }
  .topbar{ display:flex; gap:0.5rem; flex-wrap:wrap; align-items:center; justify-content:center; margin-bottom:0.75rem; width:100%; max-width:1100px; }
  .control, select, button, input[type=file] {
    background:var(--panel); color:inherit; border:1px solid #21262d;
    padding:8px 12px; border-radius:8px; font-weight:600; cursor:pointer;
  }
  #layout { display:grid; grid-template-columns: 1fr 320px; gap:14px; width:100%; max-width:1100px; align-items:start; }
  #viewer { position:relative; background:#000; border-radius:10px; overflow:hidden; }
  video, canvas { width:100%; display:block; }
  #mainCanvas { position:absolute; left:0; top:0; pointer-events:none; }
  #sidebar { background:var(--panel); padding:12px; border-radius:10px; min-height:320px; }
  label{ display:block; font-size:0.85rem; color:var(--muted); margin-bottom:6px; }
  #status{ margin-top:10px; color:var(--muted); font-size:0.9rem; }
  @media(max-width:920px){ #layout{ grid-template-columns: 1fr; } #sidebar{ order:2; } }
</style>

<!-- TensorFlow 4.x and DeepLab -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.17.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/deeplab@0.2.3/dist/deeplab.min.js"></script>
</head>
<body>
  <h1>Video Layer — Multi-Object Segmentation</h1>

  <div class="topbar">
    <input id="videoInput" type="file" accept="video/*" class="control">
    <select id="modelBase" class="control">
      <option value="pascal">DeepLab: PASCAL</option>
      <option value="ade20k">DeepLab: ADE20K</option>
    </select>
    <button id="loadModelBtn" class="control">Load Model</button>
    <button id="segmentBtn" class="control" disabled>Segment Frame</button>
    <select id="modeSelect" class="control">
      <option value="composite">Normal</option>
      <option value="blur">Blur Background</option>
      <option value="person">Keep Person Only</option>
      <option value="transparent">Transparent</option>
    </select>
    <button id="exportBtn" class="control" disabled>Export Processed Video</button>
  </div>

  <div id="layout">
    <div id="viewer">
      <video id="video" controls playsinline></video>
      <canvas id="mainCanvas"></canvas>
    </div>
    <aside id="sidebar">
      <div id="status">Load a model, then a video.</div>
    </aside>
  </div>

<script>
const videoInput = document.getElementById("videoInput");
const video = document.getElementById("video");
const mainCanvas = document.getElementById("mainCanvas");
const ctx = mainCanvas.getContext("2d");
const statusEl = document.getElementById("status");
const loadModelBtn = document.getElementById("loadModelBtn");
const modelBase = document.getElementById("modelBase");
const segmentBtn = document.getElementById("segmentBtn");
const modeSelect = document.getElementById("modeSelect");
const exportBtn = document.getElementById("exportBtn");

let model = null;
let segMap = null;
let maskCanvas = null;
let recording = false;
let mediaRecorder, recordedChunks = [];

function setStatus(msg){ statusEl.textContent = msg; console.log(msg); }

loadModelBtn.onclick = async () => {
  try {
    setStatus("Loading DeepLab model...");
    loadModelBtn.disabled = true;
    model = await deeplab.load({ base: modelBase.value });
    setStatus("Model loaded successfully.");
    loadModelBtn.textContent = "Loaded";
    loadModelBtn.disabled = true;
  } catch (err) {
    console.error(err);
    setStatus("Failed to load model: " + err.message);
    loadModelBtn.disabled = false;
  }
};

videoInput.onchange = (e) => {
  const file = e.target.files[0];
  if (!file) return;
  const url = URL.createObjectURL(file);
  video.src = url;
  video.onloadedmetadata = () => {
    mainCanvas.width = video.videoWidth;
    mainCanvas.height = video.videoHeight;
    setStatus(`Video loaded (${video.videoWidth}×${video.videoHeight})`);
    segmentBtn.disabled = false;
    exportBtn.disabled = false;
  };
};

segmentBtn.onclick = async () => {
  if (!model || !video.src) { setStatus("Load model and video first."); return; }
  setStatus("Running segmentation...");
  const off = document.createElement("canvas");
  off.width = video.videoWidth;
  off.height = video.videoHeight;
  off.getContext("2d").drawImage(video, 0, 0, off.width, off.height);
  const result = await model.segment(off);
  segMap = result.segmentationMap;
  drawComposite();
  setStatus("Segmentation complete.");
};

function drawComposite(){
  if (!video.src) return;
  const w = mainCanvas.width = video.videoWidth;
  const h = mainCanvas.height = video.videoHeight;
  ctx.drawImage(video, 0, 0, w, h);

  if (!segMap) return;

  const mode = modeSelect.value;
  const imgData = ctx.getImageData(0,0,w,h);
  const d = imgData.data;

  for (let i=0;i<w*h;i++){
    const segVal = segMap[i];
    const off = i*4;
    if (mode === "person"){
      if (segVal !== 15) d[off+3] = 0; // keep only person (class 15)
    } else if (mode === "blur" && segVal !== 15){
      // Blur simple version: dim background
      d[off] *= 0.5; d[off+1]*=0.5; d[off+2]*=0.5;
    } else if (mode === "transparent" && segVal !== 15){
      d[off+3] = 0;
    }
  }
  ctx.putImageData(imgData,0,0);
}

video.addEventListener("play", function loop(){
  if(!video.paused && !video.ended){
    drawComposite();
    requestAnimationFrame(loop);
  }
});

exportBtn.onclick = () => {
  if (!video.src) { setStatus("Load a video first."); return; }
  if (recording) return;
  setStatus("Exporting video...");

  const stream = mainCanvas.captureStream(25);
  mediaRecorder = new MediaRecorder(stream, { mimeType: "video/webm" });
  recordedChunks = [];
  mediaRecorder.ondataavailable = e => e.data.size && recordedChunks.push(e.data);
  mediaRecorder.onstop = () => {
    const blob = new Blob(recordedChunks, { type: "video/webm" });
    const a = document.createElement("a");
    a.href = URL.createObjectURL(blob);
    a.download = "processed_video.webm";
    a.click();
    setStatus("Video export complete.");
  };
  mediaRecorder.start();
  recording = true;
  video.currentTime = 0;
  video.play();
  video.onended = () => { mediaRecorder.stop(); recording = false; };
};
</script>
</body>
</html>
