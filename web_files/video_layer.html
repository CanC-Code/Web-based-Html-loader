<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>AI Video Editor — Background Removal</title>
<link rel="stylesheet" href="style.css">
</head>
<body>

<header>
  <h1>AI Video Editor — Background Removal</h1>
  <p class="lead">Load a video, select an edit mode, preview, and download the processed output.</p>
</header>

<main>
  <section class="mediaBox">
    <div class="mediaInner">
      <input id="videoInput" type="file" accept="video/*">
      <video id="inputVideo" playsinline controls></video>
      <canvas id="outputCanvas" aria-label="Processed output"></canvas>
    </div>
  </section>

  <section class="controls">
    <button id="startBtn">Start Processing</button>
    <button id="stopBtn" disabled>Stop</button>
    <button id="playBtn" disabled>Play/Replay</button>
    <button id="saveBtn" disabled>Download Video</button>
    <select id="modeSelect" class="aux" title="Processing mode">
      <option value="remove">Background Removal</option>
      <option value="blur">Background Blur</option>
      <option value="none">No Processing</option>
    </select>
  </section>

  <div class="progressWrap">
    <div class="progress"><div id="progressFill"></div></div>
  </div>

  <div id="status">Ready.</div>
</main>

<!-- MediaPipe SelfieSegmentation -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"></script>

<script>
const videoInput = document.getElementById('videoInput');
const inputVideo = document.getElementById('inputVideo');
const outputCanvas = document.getElementById('outputCanvas');
const ctx = outputCanvas.getContext('2d');

const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const playBtn = document.getElementById('playBtn');
const saveBtn = document.getElementById('saveBtn');
const modeSelect = document.getElementById('modeSelect');
const progressFill = document.getElementById('progressFill');
const statusEl = document.getElementById('status');

let processing = false;
let recordedBlobs = [];
let frames = [];
let recorder = null;

function setStatus(s){ statusEl.textContent = s; }
function setProgress(p){ progressFill.style.width = `${Math.max(0, Math.min(100,p))}%`; }

// --- Load video ---
videoInput.addEventListener('change', e => {
  const file = e.target.files[0];
  if (!file) return;
  inputVideo.src = URL.createObjectURL(file);
  inputVideo.load();
  inputVideo.onloadeddata = () => {
    outputCanvas.width = inputVideo.videoWidth;
    outputCanvas.height = inputVideo.videoHeight;
    setStatus(`Loaded: ${inputVideo.videoWidth}×${inputVideo.videoHeight}`);
    startBtn.disabled = false;
    stopBtn.disabled = true;
    playBtn.disabled = true;
    saveBtn.disabled = true;
    recordedBlobs = [];
    frames = [];
  };
});

// --- Initialize MediaPipe ---
const segmentation = new SelfieSegmentation({ locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${f}` });
segmentation.setOptions({ modelSelection: 1 }); // 0 = general, 1 = landscape
segmentation.onResults(onSegmentationResults);

let maskFrame = null;

function onSegmentationResults(results){
  maskFrame = results.segmentationMask;
}

// --- Start processing ---
startBtn.addEventListener('click', ()=>{
  if(!inputVideo.src){ setStatus('Select a video first.'); return; }
  processing = true;
  startBtn.disabled = true;
  stopBtn.disabled = false;
  modeSelect.disabled = true;
  frames = [];
  recordedBlobs = [];

  inputVideo.currentTime = 0;
  inputVideo.play().catch(()=>{});
  setStatus('Processing started...');

  // Capture stream for recording
  const stream = outputCanvas.captureStream(25);
  recorder = new MediaRecorder(stream, { mimeType: 'video/webm;codecs=vp8' });
  recorder.ondataavailable = ev => { if(ev.data.size) recordedBlobs.push(ev.data); };
  recorder.start(1000);

  processLoop();
});

// --- Stop processing ---
stopBtn.addEventListener('click', ()=>{
  processing = false;
  startBtn.disabled = false;
  stopBtn.disabled = true;
  modeSelect.disabled = false;
  playBtn.disabled = frames.length>0;
  saveBtn.disabled = recordedBlobs.length>0;
  if(recorder && recorder.state==='recording') recorder.stop();
  setStatus('Processing stopped.');
});

// --- Play/Replays processed frames ---
playBtn.addEventListener('click', ()=>{
  if(frames.length===0) return;
  let idx = 0;
  function playFrame(){
    if(idx>=frames.length) return;
    ctx.putImageData(frames[idx],0,0);
    idx++;
    requestAnimationFrame(playFrame);
  }
  playFrame();
});

// --- Download processed video ---
saveBtn.addEventListener('click', ()=>{
  if(recordedBlobs.length===0){ setStatus('Nothing recorded.'); return; }
  const blob = new Blob(recordedBlobs,{type:'video/webm'});
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = `processed_${Date.now()}.webm`;
  a.click();
  setStatus('Video downloaded.');
});

// --- Processing loop ---
async function processLoop(){
  if(!processing) return;
  ctx.drawImage(inputVideo,0,0,outputCanvas.width,outputCanvas.height);

  if(maskFrame){
    const mode = modeSelect.value;
    ctx.save();
    if(mode==='remove'){
      ctx.globalCompositeOperation = 'destination-in';
      ctx.drawImage(maskFrame,0,0,outputCanvas.width,outputCanvas.height);
    } else if(mode==='blur'){
      ctx.filter = 'blur(8px)';
      ctx.globalCompositeOperation = 'destination-over';
      ctx.drawImage(maskFrame,0,0,outputCanvas.width,outputCanvas.height);
    }
    ctx.restore();
  }

  frames.push(ctx.getImageData(0,0,outputCanvas.width,outputCanvas.height));

  if(inputVideo.duration && !isNaN(inputVideo.duration)){
    const pct = Math.min(100,(inputVideo.currentTime/inputVideo.duration)*100);
    setProgress(pct);
  }

  if(inputVideo.currentTime<inputVideo.duration){
    requestAnimationFrame(processLoop);
  } else {
    processing = false;
    stopBtn.disabled = true;
    startBtn.disabled = false;
    playBtn.disabled = true;
    saveBtn.disabled = recordedBlobs.length>0;
    setStatus('Processing finished.');
    if(recorder && recorder.state==='recording') recorder.stop();
  }

  // Feed video frame to MediaPipe
  if(processing && !inputVideo.paused && !inputVideo.ended){
    segmentation.send({image: inputVideo});
  }
}
</script>

</body>
</html>